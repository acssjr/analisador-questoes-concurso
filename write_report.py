import os

# Create output directory
os.makedirs('.claude/cache/agents/scout', exist_ok=True)

report = """# An√°lise de Capacidade e Custo de Tokens
Generated: 2026-01-12

## Sum√°rio Executivo

O sistema atualmente processa **1 prova (60 quest√µes) em ~30 segundos** usando **46,728 tokens** via Groq API (Llama 4 Scout). O **GARGALO PRINCIPAL √© TPM (Tokens Per Minute)**, limitando a capacidade a **~0.64 provas/minuto** ou **~38 provas/hora**.

Para processar **20 provas simultaneamente**, o tempo estimado √© **~32 minutos** sequencialmente. O sistema **N√ÉO possui filas ou processamento ass√≠ncrono**, bloqueando durante uploads.

---

## 1. M√©tricas Atuais (1 Prova de 60 Quest√µes)

### Token Usage
```
Total de tokens: 46,728
Chamadas API: 7 (batch de 3 p√°ginas cada)
Tempo de processamento: ~30 segundos
P√°ginas processadas: 16 p√°ginas
Tokens por p√°gina: ~2,920
Tokens por quest√£o: ~779
```

### Distribui√ß√£o de Tokens por Batch
```
Batch 1 (p√°ginas 3-5):   9,323 tokens
Batch 2 (p√°ginas 6-8):   9,129 tokens
Batch 3 (p√°ginas 9-11):  9,064 tokens
Batch 4 (p√°ginas 12-14): 3,640 tokens
Batch 5 (p√°ginas 15-16): 1,631 tokens
Metadata (edital):       10,802 tokens
Conte√∫do program√°tico:   3,139 tokens
```

---

## 2. Limites da API Groq

### Llama 4 Scout (Free Tier) - Estimativas
```
RPM (Requests Per Minute): ~30 requisi√ß√µes/minuto
TPM (Tokens Per Minute):   ~30,000-50,000 tokens/minuto
Rate Limiting:             Exponential backoff (1s, 2s, 4s)
Max Retries:               3 tentativas
```

---

## 3. Gargalos Identificados

| Fator | Limite | Capacidade | C√°lculo |
|-------|--------|------------|---------|
| **Tokens (TPM)** | 30,000/min | **0.64 provas/min** | 30,000 / 46,728 |
| Requests (RPM) | 30/min | 4.3 provas/min | 30 / 7 |

**GARGALO PRINCIPAL: TOKENS (TPM)**

Capacidade: ~38 provas/hora

---

## 4. Cen√°rios de Escala

| Quantidade | Tempo Estimado | Tokens Totais |
|------------|----------------|---------------|
| 1 prova    | ~1.5 min       | 46,728        |
| 5 provas   | ~8 min         | 233,640       |
| 10 provas  | ~16 min        | 467,280       |
| **20 provas** | **~32 min** | **934,560**   |
| 50 provas  | ~78 min        | 2,336,400     |

---

## 5. Arquitetura Atual

### C√≥digo Relevante

**Upload Endpoint**: `C:\Users\Ant√¥nio\Documents\analisador-questoes-concurso\src\api\routes\upload.py:23-145`

**Extractor**: `C:\Users\Ant√¥nio\Documents\analisador-questoes-concurso\src\extraction\prova_extractor.py:85-173`
- Batch size: 3 p√°ginas por chamada API
- Processamento sequencial (s√≠ncrono)

**Groq Client**: `C:\Users\Ant√¥nio\Documents\analisador-questoes-concurso\src\llm\providers\groq_client.py:31-116`
- MAX_RETRIES: 3
- BASE_DELAY: 1 segundo
- Exponential backoff em rate limits

---

## 6. Limita√ß√µes Atuais

### Infraestrutura
- ‚ùå **Sem sistema de filas** (Redis/Celery)
- ‚ùå **Sem processamento ass√≠ncrono** de m√∫ltiplas provas
- ‚ùå **Uploads bloqueantes** (frontend aguarda 30s por prova)
- ‚ùå **Sem rate limiting interno**
- ‚ùå **Sem progress tracking**

### Resili√™ncia
- ‚úÖ Retry com exponential backoff (3 tentativas)
- ‚ùå **Sem fallback para outros LLMs**
- ‚ùå **Sem cache de resultados**

---

## 7. Recomenda√ß√µes

### üü¢ Curto Prazo (0-2 semanas) - At√© 50 Provas/Dia
**STATUS**: Sistema atual **SUFICIENTE**

1. Adicionar progress feedback no frontend
2. Implementar cache de taxonomias (Redis ou in-memory)
3. Melhorar logging de tokens

### üü° M√©dio Prazo (2-4 semanas) - 100-500 Provas/Dia
**STATUS**: Necess√°rio **SISTEMA DE FILAS**

Implementar:
- Redis (queue + cache)
- Celery (task queue)
- Rate limiter interno
- Worker pool (3-5 workers)

### üî¥ Longo Prazo (1-3 meses) - 1000+ Provas/Dia

Implementar:
- Auto-scaling de workers
- Multi-provider LLM (Groq ‚Üí Anthropic fallback)
- Monitoring (Prometheus + Grafana)
- Database optimization

---

## 8. Compara√ß√£o de Custos

### Free Tier + Filas (Recomendado MVP)
```
- Groq Free Tier: $0/m√™s
- Redis Cloud: $0/m√™s (250MB)
- VPS: ~$10/m√™s
Total: ~$10/m√™s
Capacidade: ~1000 provas/m√™s
```

### Paid API + Filas
```
- Groq Paid: ~$7/m√™s (estimativa)
- Redis: $10/m√™s
- VPS: ~$20/m√™s
Total: ~$37/m√™s
Capacidade: Ilimitada
```

---

## 9. Pr√≥ximos Passos (Prioridade)

### P0 (Cr√≠tico) - Semana 1
- [ ] Progress indicator no frontend
- [ ] Cache de taxonomias
- [ ] Melhorar error handling

### P1 (Importante) - Semanas 2-3
- [ ] Setup Redis + Celery
- [ ] Task queue implementation
- [ ] Rate limiter interno
- [ ] Status endpoint

### P2 (Desej√°vel) - Semana 4
- [ ] Fallback para Anthropic
- [ ] Monitoring dashboard

---

## Conclus√£o

**Sistema atual funciona bem para uso de baixa escala** (~50 provas/dia).

Para escalar:
1. **Imediato**: Adicionar Redis + Celery (2-3 dias)
2. **Custo**: ~$10/m√™s infraestrutura
3. **Capacidade**: 100-500 provas/dia com filas
"""

with open('.claude/cache/agents/scout/latest-output.md', 'w', encoding='utf-8') as f:
    f.write(report)

print('‚úì Report written to .claude/cache/agents/scout/latest-output.md')
